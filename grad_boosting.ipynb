{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг своими руками\n",
    "\n",
    "**Внимание:** в тексте задания произошли изменения - поменялось число деревьев (теперь 50), правило изменения величины шага в задании 3 и добавился параметр `random_state` у решающего дерева. Правильные ответы не поменялись, но теперь их проще получить. Также исправлена опечатка в функции `gbm_predict`.\n",
    "\n",
    "В этом задании будет использоваться датасет `boston` из `sklearn.datasets`. Оставьте последние 25% объектов для контроля качества, разделив `X` и `y` на `X_train`, `y_train` и `X_test`, `y_test`.\n",
    "\n",
    "Целью задания будет реализовать простой вариант градиентного бустинга над регрессионными деревьями для случая квадратичной функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.20.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "X,y = load_boston(return_X_y=True)\n",
    "print y\n",
    "\n",
    "#print type(boston)\n",
    "\n",
    "sk.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Как вы уже знаете из лекций, **бустинг** - это метод построения композиций базовых алгоритмов с помощью последовательного добавления к текущей композиции нового алгоритма с некоторым коэффициентом. \n",
    "\n",
    "Градиентный бустинг обучает каждый новый алгоритм так, чтобы он приближал антиградиент ошибки по ответам композиции на обучающей выборке. Аналогично минимизации функций методом градиентного спуска, в градиентном бустинге мы подправляем композицию, изменяя алгоритм в направлении антиградиента ошибки.\n",
    "\n",
    "Воспользуйтесь формулой из лекций, задающей ответы на обучающей выборке, на которые нужно обучать новый алгоритм (фактически это лишь чуть более подробно расписанный градиент от ошибки), и получите частный ее случай, если функция потерь `L` - квадрат отклонения ответа композиции `a(x)` от правильного ответа `y` на данном `x`.\n",
    "\n",
    "Если вы давно не считали производную самостоятельно, вам поможет таблица производных элементарных функций (которую несложно найти в интернете) и правило дифференцирования сложной функции. После дифференцирования квадрата у вас возникнет множитель 2 — т.к. нам все равно предстоит выбирать коэффициент, с которым будет добавлен новый базовый алгоритм, проигноируйте этот множитель при дальнейшем построении алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "f′(L)=(a(x)−y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Заведите массив для объектов `DecisionTreeRegressor` (будем их использовать в качестве базовых алгоритмов) и для вещественных чисел (это будут коэффициенты перед базовыми алгоритмами). \n",
    "\n",
    "В цикле от обучите последовательно 50 решающих деревьев с параметрами `max_depth=5` и `random_state=42` (остальные параметры - по умолчанию). В бустинге зачастую используются сотни и тысячи деревьев, но мы ограничимся 50, чтобы алгоритм работал быстрее, и его было проще отлаживать (т.к. цель задания разобраться, как работает метод). Каждое дерево должно обучаться на одном и том же множестве объектов, но ответы, которые учится прогнозировать дерево, будут меняться в соответствие с полученным в задании 1 правилом. \n",
    "\n",
    "Попробуйте для начала всегда брать коэффициент равным 0.9. Обычно оправдано выбирать коэффициент значительно меньшим - порядка 0.05 или 0.1, но т.к. в нашем учебном примере на стандартном датасете будет всего 50 деревьев, возьмем для начала шаг побольше.\n",
    "\n",
    "В процессе реализации обучения вам потребуется функция, которая будет вычислять прогноз построенной на данный момент композиции деревьев на выборке `X`:\n",
    "\n",
    "```\n",
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]\n",
    "(считаем, что base_algorithms_list - список с базовыми алгоритмами, coefficients_list - список с коэффициентами перед алгоритмами)\n",
    "```\n",
    "\n",
    "Эта же функция поможет вам получить прогноз на контрольной выборке и оценить качество работы вашего алгоритма с помощью `mean_squared_error` в `sklearn.metrics`. \n",
    "\n",
    "Возведите результат в степень 0.5, чтобы получить `RMSE`. Полученное значение `RMSE` — **ответ в пункте 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.258124603131531 trees =  0\n",
      "4.671153714252575 trees =  1\n",
      "4.902307279003964 trees =  2\n",
      "4.964147618734462 trees =  3\n",
      "5.20526450047539 trees =  4\n",
      "5.135565602127196 trees =  5\n",
      "5.240746955112687 trees =  6\n",
      "5.289270262665006 trees =  7\n",
      "5.474743913112659 trees =  8\n",
      "5.487351059181249 trees =  9\n",
      "5.493005009464348 trees =  10\n",
      "5.486541185059444 trees =  11\n",
      "5.4853194033329675 trees =  12\n",
      "5.491142418867945 trees =  13\n",
      "5.423428938252165 trees =  14\n",
      "5.455189053902553 trees =  15\n",
      "5.45390363694601 trees =  16\n",
      "5.442535087357118 trees =  17\n",
      "5.451577011033649 trees =  18\n",
      "5.450957836386992 trees =  19\n",
      "5.455454044759812 trees =  20\n",
      "5.452830834182109 trees =  21\n",
      "5.45348230204136 trees =  22\n",
      "5.45695518901364 trees =  23\n",
      "5.458596919959244 trees =  24\n",
      "5.459704629835099 trees =  25\n",
      "5.458441954443331 trees =  26\n",
      "5.459544166421456 trees =  27\n",
      "5.4746407805902315 trees =  28\n",
      "5.455978129276081 trees =  29\n",
      "5.456647037889841 trees =  30\n",
      "5.456688163206119 trees =  31\n",
      "5.455058703113296 trees =  32\n",
      "5.454889250486015 trees =  33\n",
      "5.4547065629399745 trees =  34\n",
      "5.4557221865242145 trees =  35\n",
      "5.457191365628316 trees =  36\n",
      "5.456554727051719 trees =  37\n",
      "5.454952037148748 trees =  38\n",
      "5.455773037269918 trees =  39\n",
      "5.455668105961868 trees =  40\n",
      "5.455288876875158 trees =  41\n",
      "5.454690240227694 trees =  42\n",
      "5.454942493332569 trees =  43\n",
      "5.455052873471147 trees =  44\n",
      "5.455672101390549 trees =  45\n",
      "5.455659629260789 trees =  46\n",
      "5.455729646399097 trees =  47\n",
      "5.455680205433293 trees =  48\n",
      "5.455565103009407 trees =  49\n",
      "5.455565103009407\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "base_algorithms_list = []\n",
    "coefficients_list = []\n",
    "\n",
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]\n",
    "\n",
    "y_agrad = np.array(y_train)\n",
    "      \n",
    "for i in range(n):\n",
    "    rfc = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    rfc.fit(X_train, y_agrad)\n",
    "    base_algorithms_list.append(rfc)\n",
    "    coefficients_list.append(0.9)\n",
    "    y_p = gbm_predict(X_train)\n",
    "    y_agrad = -(y_p - y_train)\n",
    "    print mean_squared_error(y_true=y_test, y_pred=gbm_predict(X_test))**0.5, 'trees = ' ,i\n",
    "\n",
    "\n",
    "print mean_squared_error(y_true=y_test, y_pred=gbm_predict(X_test))**0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Вас может также беспокоить, что двигаясь с постоянным шагом, вблизи минимума ошибки ответы на обучающей выборке меняются слишком резко, перескакивая через минимум. \n",
    "\n",
    "Попробуйте уменьшать вес перед каждым алгоритмом с каждой следующей итерацией по формуле `0.9 / (1.0 + i)`, где `i` - номер итерации (от 0 до 49). Используйте качество работы алгоритма как **ответ в пункте 3**. \n",
    "\n",
    "В реальности часто применяется следующая стратегия выбора шага: как только выбран алгоритм, подберем коэффициент перед ним численным методом оптимизации таким образом, чтобы отклонение от правильных ответов было минимальным. Мы не будем предлагать вам реализовать это для выполнения задания, но рекомендуем попробовать разобраться с такой стратегией и реализовать ее при случае для себя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.258124603131531 trees =  0\n",
      "4.411594948336074 trees =  1\n",
      "4.391183171661546 trees =  2\n",
      "4.458775073285299 trees =  3\n",
      "4.498661031729782 trees =  4\n",
      "4.5168152101676124 trees =  5\n",
      "4.550526944390747 trees =  6\n",
      "4.609092468715132 trees =  7\n",
      "4.633987574593338 trees =  8\n",
      "4.651558505714779 trees =  9\n",
      "4.659211687810462 trees =  10\n",
      "4.665846192244086 trees =  11\n",
      "4.687756339977888 trees =  12\n",
      "4.705212386904845 trees =  13\n",
      "4.7088863892092485 trees =  14\n",
      "4.727160820532567 trees =  15\n",
      "4.738601041184405 trees =  16\n",
      "4.7434294144854805 trees =  17\n",
      "4.74795777140869 trees =  18\n",
      "4.754535803819598 trees =  19\n",
      "4.760702807935853 trees =  20\n",
      "4.76469042919606 trees =  21\n",
      "4.764828870587974 trees =  22\n",
      "4.763080541850576 trees =  23\n",
      "4.763091173078234 trees =  24\n",
      "4.762268473295418 trees =  25\n",
      "4.758055256544697 trees =  26\n",
      "4.768499657813315 trees =  27\n",
      "4.771804663740966 trees =  28\n",
      "4.780389023483233 trees =  29\n",
      "4.776576317235817 trees =  30\n",
      "4.783744654359199 trees =  31\n",
      "4.7865280216634964 trees =  32\n",
      "4.788442367935862 trees =  33\n",
      "4.787212053443569 trees =  34\n",
      "4.792422462196972 trees =  35\n",
      "4.793468730432273 trees =  36\n",
      "4.799464117150889 trees =  37\n",
      "4.804033058481719 trees =  38\n",
      "4.8038723728476995 trees =  39\n",
      "4.803086837269195 trees =  40\n",
      "4.804028978406078 trees =  41\n",
      "4.805470455205758 trees =  42\n",
      "4.804790977053986 trees =  43\n",
      "4.803709717063459 trees =  44\n",
      "4.804773448498893 trees =  45\n",
      "4.808927271733807 trees =  46\n",
      "4.808240835910818 trees =  47\n",
      "4.8088789815351305 trees =  48\n",
      "4.812550945781194 trees =  49\n",
      "4.812550945781194\n"
     ]
    }
   ],
   "source": [
    "base_algorithms_list = []\n",
    "coefficients_list = []\n",
    "\n",
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]\n",
    "\n",
    "y_agrad = np.array(y_train)\n",
    "      \n",
    "for i in range(n):\n",
    "    rfc = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "    rfc.fit(X_train, y_agrad)\n",
    "    base_algorithms_list.append(rfc)\n",
    "    coefficients_list.append(0.9 / (1.0 + i))\n",
    "    y_p = gbm_predict(X_train)\n",
    "    y_agrad = -(y_p - y_train)\n",
    "    print mean_squared_error(y_true=y_test, y_pred=gbm_predict(X_test))**0.5, 'trees = ' ,i\n",
    "\n",
    "\n",
    "print mean_squared_error(y_true=y_test, y_pred=gbm_predict(X_test))**0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "Реализованный вами метод - градиентный бустинг над деревьями - очень популярен в машинном обучении. Он представлен как в самой библиотеке `sklearn`, так и в сторонней библиотеке `XGBoost`, которая имеет свой питоновский интерфейс. На практике `XGBoost` работает заметно лучше `GradientBoostingRegressor` из `sklearn`, но для этого задания вы можете использовать любую реализацию. \n",
    "\n",
    "Исследуйте, переобучается ли градиентный бустинг с ростом числа итераций (и подумайте, почему), а также с ростом глубины деревьев. На основе наблюдений выпишите через пробел номера правильных из приведенных ниже утверждений в порядке возрастания номера (это будет **ответ в п.4**):\n",
    "\n",
    "    1. С увеличением числа деревьев, начиная с некоторого момента, качество работы градиентного бустинга не меняется существенно.\n",
    "\n",
    "    2. С увеличением числа деревьев, начиная с некоторого момента, градиентный бустинг начинает переобучаться.\n",
    "\n",
    "    3. С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга на тестовой выборке начинает ухудшаться.\n",
    "\n",
    "    4. С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга перестает существенно изменяться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_trees = [1] + range(10, 1500, 5) \n",
    "\n",
    "\n",
    "scoring = []\n",
    "for n_tree in n_trees:\n",
    "    estimator = xgb.XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=n_tree,min_child_weight=3)\n",
    "    score = cross_val_score(estimator, X, y, cv = 3)    \n",
    "    scoring.append(score)\n",
    "scoring = np.asmatrix(scoring)\n",
    "pylab.plot(n_trees, scoring.mean(axis = 1), marker='.')\n",
    "pylab.grid(True)\n",
    "pylab.xlabel('n_trees')\n",
    "pylab.ylabel('score')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С увеличением числа деревьев, начиная с некоторого момента, градиентный бустинг начинает переобучаться.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "max_depths = [1] + range(10, 100, 2) \n",
    "\n",
    "print max_depths\n",
    "\n",
    "scoring = []\n",
    "for max_d in max_depths:\n",
    "    estimator = xgb.XGBRegressor(learning_rate=0.1, max_depth=max_d, n_estimators=30,min_child_weight=3)\n",
    "    score = cross_val_score(estimator, X, y, cv = 3)    \n",
    "    scoring.append(score)\n",
    "scoring = np.asmatrix(scoring)\n",
    "pylab.plot(max_depths, scoring.mean(axis = 1), marker='.')\n",
    "pylab.grid(True)\n",
    "pylab.xlabel('max_depth')\n",
    "pylab.ylabel('score')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " С ростом глубины деревьев, начиная с некоторого момента, качество работы градиентного бустинга на тестовой выборке начинает ухудшаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "\n",
    "Сравните получаемое с помощью градиентного бустинга качество с качеством работы линейной регрессии. \n",
    "\n",
    "Для этого обучите `LinearRegression` из `sklearn.linear_model` (с параметрами по умолчанию) на обучающей выборке и оцените для прогнозов полученного алгоритма на тестовой выборке `RMSE`. Полученное качество - ответ в **пункте 5**. \n",
    "\n",
    "В данном примере качество работы простой модели должно было оказаться хуже, но не стоит забывать, что так бывает не всегда. В заданиях к этому курсу вы еще встретите пример обратной ситуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.254979753549124"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg =  LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "mean_squared_error(y_true=y_test, y_pred=lin_reg.predict(X_test))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
